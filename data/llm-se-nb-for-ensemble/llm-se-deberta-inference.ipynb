{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# # Quick Save\n",
    "# import os\n",
    "# if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     ! touch submission.csv\n",
    "#     import sys\n",
    "#     sys.exit(0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:37:58.184764Z",
     "iopub.execute_input": "2023-10-05T13:37:58.185401Z",
     "iopub.status.idle": "2023-10-05T13:37:58.192286Z",
     "shell.execute_reply.started": "2023-10-05T13:37:58.185364Z",
     "shell.execute_reply": "2023-10-05T13:37:58.191217Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install --quiet --use-deprecated=legacy-resolver --no-index /kaggle/input/llm-se-python-wheel/llm_science_exam-0.0.1-py3-none-any.whl --find-links /kaggle/input/llm-se-required-libs-python-wheels"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-10-05T13:37:58.201528Z",
     "iopub.execute_input": "2023-10-05T13:37:58.201839Z",
     "iopub.status.idle": "2023-10-05T13:38:13.992799Z",
     "shell.execute_reply.started": "2023-10-05T13:37:58.201811Z",
     "shell.execute_reply": "2023-10-05T13:38:13.991510Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# checkpoint_path = \"/kaggle/input/llm-se-deberta-v3-large-weights\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:38:13.995529Z",
     "iopub.execute_input": "2023-10-05T13:38:13.995931Z",
     "iopub.status.idle": "2023-10-05T13:38:14.000626Z",
     "shell.execute_reply.started": "2023-10-05T13:38:13.995894Z",
     "shell.execute_reply": "2023-10-05T13:38:13.999574Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import llm_science_exam.model.deberta\n",
    "import llm_science_exam.data.config\n",
    "import llm_science_exam.open_book_v2.tf_idf\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n",
    "import ctypes\n",
    "\n",
    "\n",
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "llm_science_exam.model.deberta.custom_forward_method.enable_memory_efficient_forward_method()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:38:14.001621Z",
     "iopub.execute_input": "2023-10-05T13:38:14.002081Z",
     "iopub.status.idle": "2023-10-05T13:38:28.221309Z",
     "shell.execute_reply.started": "2023-10-05T13:38:14.002051Z",
     "shell.execute_reply": "2023-10-05T13:38:28.220376Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config = llm_science_exam.data.config.get_config_from_checkpoint(checkpoint_path, drop_log_history=True)\n",
    "config"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:38:28.223772Z",
     "iopub.execute_input": "2023-10-05T13:38:28.224097Z",
     "iopub.status.idle": "2023-10-05T13:38:28.243605Z",
     "shell.execute_reply.started": "2023-10-05T13:38:28.224069Z",
     "shell.execute_reply": "2023-10-05T13:38:28.242559Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "# \n",
    "import os\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    dataset_type = \"test\"\n",
    "else:\n",
    "    dataset_type = \"train\"\n",
    "#     \n",
    "# df = pd.read_csv(f\"/kaggle/input/kaggle-llm-science-exam/{dataset_type}.csv\")\n",
    "# \n",
    "# \n",
    "# # # 4000 validation\n",
    "# # if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "# #     extra_df = pd.read_csv(\"/kaggle/input/llm-se-extra-train-datasets/takeshisuzuki/additional-dataset-800articles-4000rows/additional_dataset_800articles_4000rows.csv\")\n",
    "# #     extra_df = extra_df.dropna().reset_index(drop=True)\n",
    "# # #     df = extra_df\n",
    "# #     df = pd.concat([df, extra_df]).reset_index(drop=True)\n",
    "# \n",
    "# # # +300 validation\n",
    "# # if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "# #     extra_df = pd.read_csv(\"/kaggle/input/llm-se-extra-train-datasets/yalickj/dataset-wiki-new-1/dataset_wiki_new_1_balanced.csv\")\n",
    "# #     df = pd.concat([df, extra_df]).reset_index(drop=True)\n",
    "# \n",
    "# \n",
    "# # if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "# #    df = pd.concat([df] * (4000 // len(df))).reset_index(drop=True)\n",
    "# #    df[\"id\"] = np.arange(len(df))\n",
    "# \n",
    "# # if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "# #     for col in [\"prompt\", \"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "# #         for _ in range(10 - 1):\n",
    "# #             df[col] = df[col] + df[col]\n",
    "# \n",
    "# \n",
    "# id_list = df[\"id\"].to_numpy()\n",
    "# \n",
    "# if \"answer\" in df.columns:\n",
    "#     answers = df[\"answer\"].to_numpy()\n",
    "# else:\n",
    "#     answers = None\n",
    "# \n",
    "# df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:38:28.245252Z",
     "iopub.execute_input": "2023-10-05T13:38:28.245918Z",
     "iopub.status.idle": "2023-10-05T13:38:28.287880Z",
     "shell.execute_reply.started": "2023-10-05T13:38:28.245885Z",
     "shell.execute_reply": "2023-10-05T13:38:28.286982Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !cp -r /kaggle/input/all-paraphs-parsed-expanded /kaggle/working/\n",
    "# \n",
    "# df[\"context\"] = llm_science_exam.open_book_v2.tf_idf.get_context(\n",
    "#     df,\n",
    "#     wiki_dataset_paths=[\n",
    "#         \"/kaggle/working/all-paraphs-parsed-expanded\",\n",
    "# #         \"/kaggle/input/llm-se-additional-wiki-stem-articles\"\n",
    "#     ],\n",
    "#     num_titles=3,\n",
    "# #     num_titles=10,\n",
    "# )\n",
    "# \n",
    "# print(df.iloc[0])\n",
    "# df.to_csv(f\"{dataset_type}.csv\", index=False)\n",
    "# del df\n",
    "# \n",
    "# clean_memory()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:38:28.289373Z",
     "iopub.execute_input": "2023-10-05T13:38:28.290061Z",
     "iopub.status.idle": "2023-10-05T13:46:45.666763Z",
     "shell.execute_reply.started": "2023-10-05T13:38:28.290028Z",
     "shell.execute_reply": "2023-10-05T13:46:45.665740Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": dataset_with_context_path})[\"train\"]\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenized_dataset = llm_science_exam.model.deberta.dataset.map_preprocess(\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "#         max_length=2 * 1024,\n",
    "#         max_length=int(1.5 * 1024),\n",
    "    with_answer=False,\n",
    "    max_length=1024,\n",
    "    num_proc=None,\n",
    ")\n",
    "    \n",
    "del dataset, tokenizer\n",
    "clean_memory()\n",
    "\n",
    "df = tokenized_dataset.to_pandas()\n",
    "del tokenized_dataset\n",
    "clean_memory()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:46:45.668472Z",
     "iopub.execute_input": "2023-10-05T13:46:45.668868Z",
     "iopub.status.idle": "2023-10-05T13:47:12.757429Z",
     "shell.execute_reply.started": "2023-10-05T13:46:45.668829Z",
     "shell.execute_reply": "2023-10-05T13:47:12.756496Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# probs = np.random.random((len(df), 5))\n",
    "# probs /= np.sum(probs, axis=1, keepdims=True)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def run_model(device: int, df):\n",
    "    model, tokenizer = llm_science_exam.model.deberta.model.get_model_from_checkpoint(config[\"model\"], checkpoint_path)\n",
    "    model.to(f\"cuda:{device}\")\n",
    "    model.half()\n",
    "    model.eval()\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        Dataset.from_pandas(df),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=llm_science_exam.model.deberta.dataset.DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    )\n",
    "    \n",
    "    probs = []\n",
    "    for batch in tqdm(data_loader, desc=f\"inference on device cuda:{device}\", position=device + 1):\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            probs.append(torch.softmax(outputs.logits, dim=-1).cpu().detach().numpy())\n",
    "        del batch, outputs\n",
    "        clean_memory()\n",
    "    return np.concatenate(probs)\n",
    "\n",
    "\n",
    "# Run model\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    probs = list(executor.map(run_model, [0, 1], np.array_split(df, 2)))\n",
    "    probs = np.concatenate(probs)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:47:12.758890Z",
     "iopub.execute_input": "2023-10-05T13:47:12.759246Z",
     "iopub.status.idle": "2023-10-05T13:47:12.766915Z",
     "shell.execute_reply.started": "2023-10-05T13:47:12.759215Z",
     "shell.execute_reply": "2023-10-05T13:47:12.765912Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "del df\n",
    "clean_memory()\n",
    "pd.DataFrame(probs).to_csv(\"probs.csv\", index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:47:12.768233Z",
     "iopub.execute_input": "2023-10-05T13:47:12.769225Z",
     "iopub.status.idle": "2023-10-05T13:47:13.027067Z",
     "shell.execute_reply.started": "2023-10-05T13:47:12.769185Z",
     "shell.execute_reply": "2023-10-05T13:47:13.025813Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save results\n",
    "df = pd.read_csv(dataset_with_context_path)\n",
    "\n",
    "n = len(df)\n",
    "for i, scores in enumerate(probs):\n",
    "    top3 = np.argsort(scores)[::-1]\n",
    "    df.loc[i, 'prediction'] = ' '.join(['ABCDE'[j] for j in top3])\n",
    "df[[\"id\", 'prediction']].to_csv('submission.csv', index=False)\n",
    "\n",
    "# Display performances if train set is used\n",
    "\n",
    "def print_map_at_3(df):\n",
    "    n = len(df)\n",
    "    for i in range(n):\n",
    "        df.loc[i, 'top_1'] = df.loc[i, 'prediction'][0]\n",
    "        df.loc[i, 'top_2'] = df.loc[i, 'prediction'][2]\n",
    "        df.loc[i, 'top_3'] = df.loc[i, 'prediction'][4]\n",
    "\n",
    "    top_i = [(df[f'top_{i}'] == df[\"answer\"]).sum() for i in [1, 2, 3]]\n",
    "    print(f'top1 : {top_i[0]}/{n}, top2 : {top_i[1]}/{n}, top3 : {top_i[2]}/{n} (total={sum(top_i)} / {n})')\n",
    "    print(f'Accuracy: {100*top_i[0]/n:.1f}%, map3: {100*(top_i[0] + top_i[1]*1/2 + top_i[2]*1/3).sum()/n:.1f}%')\n",
    "\n",
    "    \n",
    "if 'answer' in df.columns:\n",
    "    if len(df) > 200:\n",
    "        print(\"Old CV:\")\n",
    "        print_map_at_3(df.iloc[:200])\n",
    "\n",
    "        print(\"\\nNew CV:\")\n",
    "    else:\n",
    "        print(\"CV:\")\n",
    "    print_map_at_3(df)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-05T13:47:13.030346Z",
     "iopub.execute_input": "2023-10-05T13:47:13.031322Z",
     "iopub.status.idle": "2023-10-05T13:47:13.142037Z",
     "shell.execute_reply.started": "2023-10-05T13:47:13.031283Z",
     "shell.execute_reply": "2023-10-05T13:47:13.140927Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
